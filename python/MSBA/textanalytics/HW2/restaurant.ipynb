{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = \"Billy Yuan, Nikita Lakhotia, Stuti Maddan, Tyler Nicolas, Wenduo Wang\"\n",
    "__copyright__ = \"Well, knowledge is open to curious minds.\"\n",
    "__license__ = \"GPL-3.0\"\n",
    "__version__ = \"0.1\"\n",
    "__maintainer__ = \"Wenduo Wang\"\n",
    "__email__ = \"wenduo.wang@utexas.edu\"\n",
    "__status__ = \"development\"\n",
    "__date__ = \"Sep/15/2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import time, re, math, functools\n",
    "from urllib2 import urlopen, Request\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from patsy import dmatrices\n",
    "from nltk import pos_tag, bigrams\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as stpwds\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lmtz = WordNetLemmatizer().lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    '''This is a decorator to return a function's running time'''\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        t2 = time.time()\n",
    "        print \"{:>10}:{:>10.3f} seconds\".format(func.__name__, t2-t1)\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def readData(portion, random_state=time.time()):\n",
    "    '''Read in a certain portion of data in a random manner'''\n",
    "    rd.seed(random_state)\n",
    "    skip = rd.sample(xrange(1, 19999), int(math.ceil(19999*(1-portion))))\n",
    "    data = pd.read_csv(\"yelp.csv\", skiprows=skip)\n",
    "    data[\"target\"]=data.stars.map(lambda v: 1 if v>3 else 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def generateTrainTest(data, portion, random_state=time.time()):\n",
    "    rd.seed(random_state)\n",
    "    train_index = rd.sample(xrange(len(data)), int(math.ceil(len(data)*portion)))\n",
    "    test_index = list(set(xrange(len(data)))-set(train_index))\n",
    "    train_data = data.ix[train_index]\n",
    "    test_data = data.ix[test_index]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def generateFormula(data):\n",
    "    formula = \"target~0\"\n",
    "    for var in data.columns.values.tolist():\n",
    "        if data[var].dtype == \"int64\" and var not in [\"stars\", \"target\", \"wc\", \"Review\", \"prediction\"]:\n",
    "            formula += \"+\"+var\n",
    "        else:\n",
    "            continue\n",
    "    return formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitXY(data):\n",
    "    Y, X = dmatrices(generateFormula(data), data=data, return_type=\"dataframe\")\n",
    "    return X, np.ravel(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_model(X, y):\n",
    "    model = LogisticRegression(random_state=128)\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printAccuracy(prediction, target):\n",
    "    print \"Accuracy: {:>6.4f}\".format((prediction == target).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review2wc(text, lem=False):\n",
    "    wc = {}\n",
    "    text = text.lower()\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    stopwords = stpwds.words(\"english\")\n",
    "    if lem:\n",
    "        lmtzi = lmtz\n",
    "        tokens = map(lmtz, tokens)\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "        \n",
    "    for token in tokens:\n",
    "        if token not in stopwords:\n",
    "            try:\n",
    "                wc[token] =+ 1\n",
    "            except KeyError:\n",
    "                wc[token] = 1\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def term_prob(corpus, subset):\n",
    "    prob_dict = {}\n",
    "    N = sum([i for (_, i) in list(corpus.items())])\n",
    "    for key in corpus:\n",
    "        if key not in subset:\n",
    "            prob_dict[key] = 1.0 / N\n",
    "        else:\n",
    "            prob_dict[key] = subset[key] + 1.0 / N\n",
    "    return prob_dict\n",
    "\n",
    "@timer\n",
    "def log_prob(term_prob_high, term_prob_low):\n",
    "    term_log_prob = {}\n",
    "    log = math.log\n",
    "    for key in term_prob_high:\n",
    "        term_log_prob[key] = log(term_prob_high[key]/term_prob_low[key])\n",
    "    return term_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def token_count(wc):\n",
    "    tc = {}\n",
    "    for dic in wc.tolist():\n",
    "        if len(dic) == 0: continue\n",
    "        for token, count in dic.items():\n",
    "            try:\n",
    "                tc[token] += count\n",
    "            except KeyError:\n",
    "                tc[token] = 1\n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def totalscore(wc, prior, benchmark):\n",
    "    prob = 0\n",
    "    for word, count in wc.items():\n",
    "        try:\n",
    "            prob += count * benchmark[word]\n",
    "        except KeyError:\n",
    "            prob += 0\n",
    "    prob += math.log(prior/(1-prior+0.00001))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NBClassifier(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.term_log_prob = None\n",
    "        self.prior = None\n",
    "    \n",
    "    def fit(self, data, x_label, y_label):\n",
    "        self.X = data[x_label]\n",
    "        self.y = data[y_label]\n",
    "        self.x_label = x_label\n",
    "        self.y_label = y_label\n",
    "        token_count_total = token_count(data[x_label])\n",
    "        token_count_high = token_count(data[data[y_label]==1][x_label])\n",
    "        token_count_low = token_count(data[data[y_label]==0][x_label])\n",
    "        term_prob_high = term_prob(token_count_total, token_count_high)\n",
    "        term_prob_low = term_prob(token_count_total, token_count_low)\n",
    "        self.term_log_prob = log_prob(term_prob_high, term_prob_low)\n",
    "        self.prior = len(data[data[y_label]==1])*1.0/len(data)\n",
    "        \n",
    "    def predict(self, test, threshold=None):\n",
    "        totalscore_partial = functools.partial(totalscore, \n",
    "                                               prior= self.prior,\n",
    "                                               benchmark=self.term_log_prob)\n",
    "        score = test[self.x_label].map(totalscore_partial)\n",
    "        if threshold == None:\n",
    "            return score\n",
    "        else:\n",
    "            prediction = score.map(lambda x: 1 if x>threshold else 0)\n",
    "            return prediction\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def positiveness(test, positive, negative, threshold=1):\n",
    "    product_positive = 0.1\n",
    "    product_negative = 0.1\n",
    "    len_positive = math.sqrt(sum(map(lambda x: x*x, positive.values())))\n",
    "    len_negative = math.sqrt(sum(map(lambda x: x*x, negative.values())))\n",
    "    for key in positive.keys():\n",
    "        try:\n",
    "            product_positive += positive[key] * test[key]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    product_positive = product_positive*1.0/len_positive    \n",
    "        \n",
    "    for key in negative.keys():\n",
    "        try:\n",
    "            product_negative += negative[key] * test[key]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    product_negative = product_negative*1.0/len_negative\n",
    "    \n",
    "    return ((product_positive*1.0/product_negative)>threshold)*1\n",
    "\n",
    "@timer\n",
    "def predRating(train, test):\n",
    "    base_vec = train.wc.tolist()\n",
    "    prediction = [0]*len(test)\n",
    "    test_vec = test.wc.tolist()\n",
    "    for i in range(len(test_vec)):\n",
    "        vecCosine_partial = functools.partial(vecCosine, test=test_vec[i])\n",
    "        cosine_list = map(vecCosine_partial, base_vec)\n",
    "        top_5 = sorted(range(len(base_vec)), key=lambda i: cosine_list[i], reverse=True)[:5]\n",
    "        prediction[i] = train.ix[top_5].stars.mean()\n",
    "    pred_star = np.array(map(lambda x: (x>3)*1, prediction))\n",
    "    return pred_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task A. Ignore the text (reviews) and run a classification model with the numeric data (you can use standard methods like logistic regression, k-nearest neighbors or anything else). What is the best accuracy of your model with numeric data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  readData:     0.116 seconds\n",
      "generateTrainTest:     0.006 seconds\n",
      "generateFormula:     0.001 seconds\n",
      "generateFormula:     0.001 seconds\n",
      "Accuracy: 0.6964\n"
     ]
    }
   ],
   "source": [
    "data = readData(0.2, random_state=6)\n",
    "train, test = generateTrainTest(data, 0.7, random_state=6)\n",
    "X, y = splitXY(data)\n",
    "model_1 = logistic_model(X, y)\n",
    "X_test, y_test = splitXY(test)\n",
    "prediction = model_1.predict(X_test)\n",
    "printAccuracy(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task B. Perform a supervised classification on a subset of the corpus using the reviews only. You can write your code in Python or R. What accuracy do you get from this text mining exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generateTrainTest:     0.004 seconds\n"
     ]
    }
   ],
   "source": [
    "data[\"wc\"] = data.Review.map(review2wc)\n",
    "train, test = generateTrainTest(data, 0.7, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_count:     0.088 seconds\n",
      "token_count:     0.029 seconds\n",
      "token_count:     0.017 seconds\n",
      " term_prob:     0.008 seconds\n",
      " term_prob:     0.009 seconds\n",
      "  log_prob:     0.006 seconds\n",
      "Accuracy: 0.7048\n"
     ]
    }
   ],
   "source": [
    "classifier = NBClassifier()\n",
    "classifier.fit(train, \"wc\", \"target\")\n",
    "prediction = classifier.predict(test, threshold=0)\n",
    "printAccuracy(prediction, test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task C. Combine the numeric data and the text classification model (in task B) to create a “hybrid” model. It is your task to figure out how to do this. Now run this hybrid classification model and compare the results with those in A and B. Does the numeric data add to the predictive power relative to text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generateTrainTest:     0.015 seconds\n",
      "generateFormula:     0.001 seconds\n",
      "generateFormula:     0.001 seconds\n",
      "Accuracy: 0.6956\n"
     ]
    }
   ],
   "source": [
    "data[\"total_score\"] = classifier.predict(data, threshold=None)\n",
    "train, test = generateTrainTest(data, 0.7, random_state=6)\n",
    "X, y = splitXY(train)\n",
    "model_2 = logistic_model(X, y)\n",
    "X_test, y_test = splitXY(test)\n",
    "prediction = model_2.predict(X_test)\n",
    "printAccuracy(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task D. Use unsupervised sentiment analysis on the reviews (with SentiStrength or any other tool) and use the sentiment scores to predict high/low rating. Compare and contrast the results of tasks B and D. What can you conclude from your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totally_positive = \"This restaurant is very good. It is actually the best on that I have ever been to.\\\n",
    "                    The queue could be long, but if you have booked well in advance it would not be a problem.\\\n",
    "                    Everyone smiles and their service is definitely professional. The foods are fantastic,\\\n",
    "                    and the price is low, I mean affordable. The wines are very nice, and there is a good collection\\\n",
    "                    of desserts which tastes phenomenal. The waiter and waitress are attentative and helpful.\\\n",
    "                    I believe they have been trained very well. Tables are clean, dishes\\\n",
    "                    served in time and they taste absolutely delicious. I totally recommend it.\"\n",
    "\n",
    "totally_negative = \"I can't believe this restaurant could be so bad. We waited for a long time before we were attended\\\n",
    "                    to by a waiter, who was so crude, maybe because he thought I couldn't afford the meal, the price of\\\n",
    "                    which by the way is riculously high. We each ordered 3 courses, but nothing showed up in the following\\\n",
    "                    30 minutes. Nobody even explained that to us. Finally I called the manager, and he just said they were\\\n",
    "                    busy. Well, I could see they were busy, but it doesn't make sense that other people were served better\\\n",
    "                    than us. And the end, we decided to give a smaller tip to the waitor (I preferred not at all), and\\\n",
    "                    I can still remember his face -- disgusting. Please don't go there!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_vec = review2wc(totally_positive)\n",
    "negative_vec = review2wc(totally_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6712\n"
     ]
    }
   ],
   "source": [
    "positiveness_partial = functools.partial(positiveness, positive=positive_vec, negative=negative_vec, threshold=.5)\n",
    "unsupervised_prediction = data.wc.map(positiveness_partial)\n",
    "printAccuracy(unsupervised_prediction, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task E. Implement the PMI approach to sentiment analysis (in either Python or R), and run the classification model with the sentiment scores. How do your results compare with those in Task D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review2list(text):\n",
    "    wc = {}\n",
    "    text = text.lower()\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    stopwords = stpwds.words(\"english\")\n",
    "    remove = tokens.remove\n",
    "    while \"\" in tokens:\n",
    "        remove(\"\")\n",
    "    for token in tokens:\n",
    "        if token in stopwords:\n",
    "            remove(token)\n",
    "    token_pos = pos_tag(tokens)\n",
    "    pos_list = map(lambda tup: tup[1])\n",
    "    pos_bigram = bigrams(pos_list)\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern_1 = [(\"JJ\", \"NN\"), (\"JJ\", \"NNS\"), \n",
    "           (\"RB\", \"VB\"), (\"RB\", \"VBD\"), (\"RB\", \"VBN\"), (\"RB\", \"VBG\"),\n",
    "          (\"RBR\", \"VB\"), (\"RBR\", \"VBD\"), (\"RBR\", \"VBN\"), (\"RBR\", \"VBG\"),\n",
    "          (\"RBS\", \"VB\"), (\"RBS\", \"VBD\"), (\"RBS\", \"VBN\"), (\"RBS\", \"VBG\")]\n",
    "pattern_2 = [(\"RB\", \"JJ\"), (\"RBR\", \"JJ\"), (\"RBS\", \"JJ\"),\n",
    "            (\"JJ\", \"JJ\"),\n",
    "            (\"NN\", \"JJ\"), (\"NNS\", \"JJ\")]\n",
    "no_match = [\"NN\", \"NNS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://www.google.com/search?q=good%20restaurant\"\n",
    "request = Request(url=url, headers={\"user-agent\":\"Chrome/53.0.2785.113\"})\n",
    "soup = BeautifulSoup(urlopen(request).read(100000), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857000000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"\".join(re.split(\"\\D+\",soup.find(\"div\", id=\"resultStats\").get_text().encode(\"utf-８\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def semanticOrientation(phrases, \n",
    "                        positive=\"excellent\", \n",
    "                        negative=\"poor\", \n",
    "                        url=\"http://www.google.com/search?q=%\",\n",
    "                        distance=5,\n",
    "                        threshold=0):\n",
    "    so_positive = 0.01\n",
    "    so_negative = 0.01\n",
    "    so_avg = 0\n",
    "    request_partial = functools.partial(Request, headers={\"user-agent\":\"Chrome/53.0.2785.113\"})\n",
    "    soup = functools.partial(BeautifulSoup, \"lxml\")\n",
    "    for phrase in phrases:\n",
    "        term = \"%22{}+{}%22+AROUND({})+%22{}%22\".format(phrase[0], distance, phrase[1])\n",
    "        request = request_partial(url=url % term)\n",
    "        s = soup(urlopen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task F. What are the top 5 “attributes” of a restaurant that are associated with (i) high and (ii) low ratings? That is, when people rate a restaurant high or low, are they more likely to mention service, ambiance, etc.? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
