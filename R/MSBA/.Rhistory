1.1^5
1.01^5
1.01^10
?choose
choose(69, 5) * 26 * 2
install.packages("swirl")
?packages.install
?package.install
?package
install.packages(swirl)
install.packages("swirl")
q()
library(swirl)
install_from_swirl("Getting and Cleaning Data")
library(httr)
bing <- handle("www.bing.com")
p1 <- GET(handle=bing, path="/")
?GET
bing <- handle("cn.bing.com")
p1 <- GET(path="/", handle=bing)
bing <- handle("http://cn.bing.com")
p1 <- GET(path="/", handle=bing)
?fromJSON
library(rJSON)
library(rjson)
?as.data.frame
?ftable
?sample
?factor
?relevel
?as.factor
lirbrary(plyr)
library(plyr)
?mutate
?log
?signif
?exp
?melt
library(reshape2)
?melt
?dcast
?ddply
help(package=data.table)
?mode
1:3
x <- c(1:3)
typeof(x)
class(x)
str(zx)
str(x)
mode(x)
storage.mode(x)
y <- c(1:2,by=0.1)
y
?c
y[3]
y <- seq(1,3)
y
y <- seq(1,3, by=0.2)
y
typeof(y)
mode(y)
storage.mode(y)
x <- seq(1,3)
x
typeof(x)
mode(x)
storage.mode(x)
?seq
typeof(mean())
typeof(mean
)
typeof(sum)
typeof(mean)
typeof(sqrt)
mode(mean)
storage.mode(mean)
?quote
?eval
eval(1+1)
eval(1+1, 2+2)
names(x)
names(y)
x <- 1:3
y <- 1:4
x == y
x & y
x < 1:8
x <- 1:8
x == y
x & y
x <- c("a", "b", "c")
y <- c(x, "d", "e")
y
x %in% y
?data.frame()
data.frame(1, 1:10)
data.frame(1:3, 1:10)
data.frame("a":"j", 1:10)
data.frame(1:10, 11:20, 21:30)
data_frame <- data.frame(1:10, 11:20, 21:30)
names(data_frame) %in%  c("a", "b", "c")
typeof(names(data_frame) %in%  c("a", "b", "c"))
data_frame[, c(T, F, T)]
data_frame[c(T, F, F, F, F, F, F, F, F, F),]
data_frame[c(F, T, F, F, F, F, F, F, F, F),]
?rep
?match
?aggregate
sum(c(T,T,F))
?grepl
?factor
?summarise_each
library(dplyr)
?summarise_each
data <- read.table(file="~/Desktop/machine-learning-ex1/ex1/ex1data1.txt")
View(data)
data <- read.table(file="~/Desktop/machine-learning-ex1/ex1/ex1data1.txt", sep=",")
View(data)
pwd()
getwd()
?read.table
?read.csv
getwd()
getwd()
read.csv("march-machine-learning-mania-2016-v1/RegularSeasonCompactResults.csv")
head(csv)
regular_compact <- read.csv("march-machine-learning-mania-2016-v1/RegularSeasonCompactResults.csv")
head(regular_compact)
str(regular_compact)
View(regular_compact)
summary(regular_compact)
?na
?na.action
mean(is.na(regular_compact$Wteam))
table(is.na(regular_compact$Wteam))
regular_detail <- read.csv("march-machine-learning-mania-2016-v1/RegularSeasonDetailedResults.csv")
head(regular_detail)
str(regular_detail)
team_label <- read.csv("march-machine-learning-mania-2016-v1/Teams.csv")
source('~/.active-rstudio-document', echo=TRUE)
str(season)
tourney_compact <- read.csv("march-machine-learning-mania-2016-v1/TourneyCompactResults.csv")
4:2i
3+2i
3+2*i
dput(season)
?month.name
month.name
pi
?pi
LETTERS
letters
ls()
tourney_compact[4, 3]
tourney_compact[[4, 3]]
tourney_compact[[3]]
any(is.na(regular_compact))
traceback()
?sample
1:254
sample(c(1:254), 254)
getwd()
write.csv
?write.csv
order <- sample(c(1:254), 254)
write.csv(order, "order.csv")
getwd
getwd()
?setdiff
library(MASS) ## a library of example datasets
library(class) ## a library with lots of classification tools
library(kknn) ## knn library
library(kknn) ## knn library
attach(Boston)
n = dim(Boston)[1]
dim(Boston)
head(Boston)
plot(lstat,medv)
train = data.frame(lstat,medv)
data.frame(lstat,medv)
head(data.frame(lstat,medv))
tail(data.frame(lstat,medv))
test = data.frame(lstat,medv)
head(train)
head(test)
ind = order(test[,1])
ind
head(ind)
?order
?kknn
getwd()
?list
library("stringdist", lib.loc="/usr/local/lib/R/site-library")
?amatch
amatch("hello", c("Hello", "hell"))
amatch("hello", c("Hello", "hell"), maxDist=1)
amatch("hello", c("He llo", "hell"), maxDist=1)
amatch("hello", c("He llo"), maxDist=1)
amatch("hello", c("He llo"), maxDist=2)
amatch("hello", c("He llo"), maxDist=3)
amatch("hello", c("He llo"), maxDist=4)
amatch("hello", c("He llo"), maxDist=5)
xx <- c(1,2,3)
rev(xx)
xx
xx[2:3]
stringdist("featureCount", "featurecount")
stringdist("featureCount", "featurecount ")
stringdist("featureCount", "featurecount  ")
stringdist("featureCount", "featurecount    ")
stringdist(c("hello", "world"), c("Hello", "World!"))
stringdist(c("hello", "world"), c("Hello", "World!", "hello"))
return 1,2
return
return(1,2)
list[[1,2], "hello"]
?list
list([1,2,3],2)
list(c("hello"),2)
list(c(1,2,3),2)
list(c(1,2,3),2) * list(c(2,2,2),10)
?mapply
mapply("*", list(c(1,2,3),2), list(c(2,2,2),10))
c(1,2,3) %*% c(1,2,3)
c(1,2,3;4,5,6)
(1,2,3;4,5,6)
[1,2,3]
scale(c(1,2,3))
library(rmarkdown)
library(rmarkdown)
?rmarkdown
#setting up the working directory
setwd("~/git/git_home/R/MSBA/")
#include dplyr library to access advanced data.frame functions
library(dplyr)
#include neuralnet library to access neural network functions
library(neuralnet)
#define the column variable types
col_classes <- c("integer",
"character",
"character",
"character",
"character",
"numeric",
"character",
"character",
"character",
"character",
"character",
"character",
"character",
"character",
"character",
"numeric",
"numeric")
#read in the whole data set
cars_data <- read.csv("Cars.csv", header = T, sep = ",", na.strings = "unsp",
colClasses=col_classes)
#this function will unfold categorical variables into different levels, NA noted as "unknown"
unfold_name <- function(variable, var_name=c("")){
subset <- as.character(unique(variable))
for (i in c(1:length(subset))){
if (is.na(subset[i])){
subset[i] <- paste("unknownn ", as.character(var_name), sep="")
}
else {
subset[i] <- paste(as.character(var_name), ": ", subset[i], sep="")
}
}
subset <- sort(subset)
return(subset)
}
#create an empty vector to store the unfolded feature names
feature_names <- c()
#store the original variable names
original_names <- colnames(cars_data)
#store the names of numerical variables
numeric_vars <- c("X", "mileage", "featureCount", "price")
#this function joins the unfolded variable names. Numeric variables remain unchanged,
#unfolded categorical variables will be expanded horizontally
for (i in c(1:ncol(cars_data))){
if (original_names[i] %in% numeric_vars){
feature_name <- original_names[i]
}
else {
feature_name <- unfold_name(cars_data[, i], original_names[i])
}
feature_names <- c(feature_names, feature_name)
}
########################################################################
#### the code below constructs new columns for unfolded variables ######
#### and a new data frame is created, including the price column. ######
#### tried to package the code in a function, but performance is  ######
#### terrible - seems multi-threading doesn't work.               ######
########################################################################
varnames <- colnames(cars_data)
varnames_logic <- feature_names[!(feature_names %in% numeric_vars)]
varnames_logic <- gsub("^.+: ", "", varnames_logic)
varnames_logic[startsWith(varnames_logic, "unknown")] <- NA
dimension <- dim(cars_data)
new_dataset <- data.frame(cars_data[, 1])
k <- 0
for (i in c(1:dimension[2])){
if (varnames[i] %in% numeric_vars){
new_dataset <- cbind(new_dataset, cars_data[, i])
}
else {
for (j in c(1:length(unique(cars_data[,i])))){
pending_col <- cars_data[, i]
if (is.na(varnames_logic[j+k])){
pending_col[!is.na(pending_col)] <- FALSE
pending_col[is.na(pending_col)] <- TRUE
}
else {
pending_col[is.na(pending_col)] <- FALSE
pending_col <- (pending_col == varnames_logic[j+k])
}
new_dataset <- cbind(new_dataset, pending_col)
}
k <- k + j
}
}
clean_dataset <- new_dataset[, 2:ncol(new_dataset)]
colnames(clean_dataset) <- feature_names
########################################################################
########################################################################
########################################################################
########################################################################
#first scale variables
#now split the training data and cross-validation data
counts <- nrow(clean_dataset)
col_num <- ncol(clean_dataset)
training_index <- sample(counts, round(counts*0.8))
training_set <- clean_dataset[training_index,]
validation_set <- clean_dataset[-training_index,]
#now split X and Y
X_train <- training_set[, -col_num]
Y_train <- training_set[, c(1, col_num)]
X_cv <- validation_set[, -col_num]
Y_cv <- validation_set[, c(1, col_num)]
# training_set_matrix <- as.numeric(as.matrix(training_set))
# training_set_matrix[training_set_matrix == TRUE] <- 1
# training_set_matrix[training_set_matrix == FALSE] <- 0
# training_set_matrix[is.na(training_set_matrix)] <- 0
# training_set_org <- data.frame(training_set_matrix)
# dim(training_set_org)
# summary(training_set_org)
formula_expression <- "`X` ~ `trim: 320`"
for (i in c(3:ncol(training_set))){
variable_quote <- paste("`", names(training_set)[i], "`", sep="")
formula_expression <- paste(formula_expression, variable_quote, sep="+")
}
formula <- as.formula(formula_expression)
training_set_converted <- model.matrix(X~., training_set)
for (i in c(1:ncol(training_set_converted))){
colnames(training_set_converted)[i] <- gsub("`|TRUE", "", colnames(training_set_converted)[i])
}
training_set_converted <- data.frame(training_set_converted)
training_set_converted$mileage <- log(training_set_converted$mileage)
training_set_converted$featureCount <- training_set_converted$featureCount^.5
# formula_expression <- "price ~ `trim..320`"
#
# for (i in c(3:(ncol(training_set_converted)-1))){
#     variable_quote <- paste("`", colnames(training_set_converted)[i], "`", sep="")
#     formula_expression <- paste(formula_expression, variable_quote, sep="+")
# }
#
# formula <- as.formula(formula_expression)
# counting <- 0
#
# for (i in c(1:ncol(training_set_converted))){
#     counting <- counting + sum(is.na(training_set_converted[,i]))
# }
#
# print(counting)
# nn <- neuralnet(
#     formula=formula,
#     data=training_set_converted,
#     hidden=10,
#     rep=5,
#     stepmax=1e+06,
#     threshold=0.01,
#     algorithm="backprop",
#     learningrate=0.01,
#     linear.output=TRUE
#     )
#
# head(nn$response)
#
# nn$act.fct
# summary(nn$net.result)
lm_model <- lm(price~., data=training_set_converted)
summary((lm_model$residuals^2)^.5)
formula_expression <- "`X` ~ `trim: 320`"
for (i in c(3:ncol(validation_set))){
variable_quote <- paste("`", names(validation_set)[i], "`", sep="")
formula_expression <- paste(formula_expression, variable_quote, sep="+")
}
formula <- as.formula(formula_expression)
validation_set_converted <- model.matrix(X~., validation_set)
for (i in c(1:ncol(validation_set_converted))){
colnames(validation_set_converted)[i] <- gsub("`|TRUE", "", colnames(validation_set_converted)[i])
}
validation_set_converted <- data.frame(validation_set_converted)
validation_set_converted$mileage <- log(validation_set_converted$mileage)
validation_set_converted$featureCount <- validation_set_converted$featureCount^.5
summary((predict(lm_model, validation_set_converted) - validation_set_converted$price)^2)^.5
#model.matrix(X~., cars_data)
lm_model_RMSE <- mean((predict(lm_model, validation_set_converted) - validation_set_converted$price)^2)^.5
lm_model_RMSE
summary(lm_model)
confint(lm_model, level=0.95)
lm_model_RMSE <- mean((predict(lm_model, validation_set_converted) - validation_set_converted$price)^2)^.5
lm_model_RMSE
