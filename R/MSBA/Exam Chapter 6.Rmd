---
title: "Chapter 6"
author: "Wenduo Wang"
date: "July 20, 2016"
output: html_document
---

Problem 9

```{r}
library(dplyr)
College <- read.csv("College.csv", header=TRUE)
```

(a) Split the College dataset into a training set containing 80% of total rows, and a test set containing the rest 20%.
```{r}
training_index <- sample(nrow(College), round(nrow(College)*0.8))
training_set <- College[training_index,]
test_set <- College[-training_index,]
```

(b) Fit a linear model using all variables except school names (`X`).
```{r}
lm_model <- lm(Apps ~ ., data=training_set[, -1])
RMSE <- mean((predict(lm_model, test_set) - test_set$Apps)^2)^.5
cat("The prediction RMSE using simple linear model is", RMSE)
```

(c) We will use the `cv.glmnet()` function supplied in `glmnet` package to do the ridge regression.
```{r}
library(glmnet)
training_set_4ridge <- model.matrix(~., data=training_set[,-c(1, 3)])
ridge_model <- cv.glmnet(x=training_set_4ridge, y=training_set$Apps, nfolds=10, alpha=0)
ridge_model_lambda <- ridge_model$lambda.1se
RMSE <- mean((predict(ridge_model, model.matrix(Apps~., test_set[, -1])) - test_set$Apps)^2)^.5
cat("The prediction RMSE using Ridge regression is", RMSE)
```

(d) For Lasso regression, the function is the same as Ridge regression, with the difference of setting `alpha=1`. The following code implements Lasso regression on the training set, and calculate the prediction RMSE on the test set.
The $\lambda$ is determined by cross-validation, all of which are printed with corresponding non-zero coefficient counts.
```{r}
lasso_model <- cv.glmnet(x=training_set_4ridge, y=training_set$Apps, nfolds=10, alpha=1)
lasso_model_lambda <- lasso_model$lambda.1se
RMSE <- mean((predict(lasso_model, model.matrix(Apps~., test_set[, -1])) - test_set$Apps)^2)^.5
cat("The prediction RMSE using Lasso regression is", RMSE)
print(data.frame("Lambda"=lasso_model$lambda, "Non-zero coefs"=lasso_model$nzero))
```

(e) 